from feather import read_dataframe as read_feather
import numpy as np
import os
import pandas as pd
import pdb
import pickle
from time import time

from zpylib import datatools
from zpylib.learn.gbm import Lgbm
from zpylib import stats
from zpylib import data_path as dp
from zpylib import model_path as mp

# Constants
TRAIN_PATHS = [dp('refactored/' + st) for st in os.listdir(dp('refactored')) if 'train_' in st]
TRAIN_PATHS.sort()
TEST_PATH = dp('refactored/test.feather')
SAMPLE_PATH = dp('submit/sample_submission.csv')
SUBMIT_PATH = dp('submit/submission.csv')
MODELS_PATH = mp('lgb_3feather.pkl')

EXTRA_PREDICTORS = ['pydens_' + str(k) for k in range(10)]
# KEEPERS = [
#     'SmartScreen', 'Census_OEMModelIdentifier', 'AvSigVersion', 'Census_FirmwareVersionIdentifier', 'CityIdentifier',
#     'continuous_AVProductStatesIdentifier', 'AVProductStatesIdentifier', 'CountryIdentifier',
#     'Census_ProcessorModelIdentifier', 'EngineVersion', 'AppVersion', 'Census_TotalPhysicalRAM', 'Census_OSVersion',
#     'Census_InternalPrimaryDiagonalDisplaySizeInInches', 'Wdft_IsGamer', 'Census_OSInstallTypeName', 'OsBuildLab',
#     'LocaleEnglishNameIdentifier', 'DefaultBrowsersIdentifier', 'IeVerIdentifier', 'GeoNameIdentifier',
#     'Census_FirmwareManufacturerIdentifier', 'SMode', 'continuous_Census_OSInstallTypeName', 'Census_OEMNameIdentifier',
#     'Census_PrimaryDiskTotalCapacity', 'continuous_AvSigVersion', 'AVProductsInstalled', 'Census_ActivationChannel',
#     'Processor', 'RtpStateBitfield', 'Census_HasOpticalDiskDrive', 'Census_OSUILocaleIdentifier'
# ]

def read_response(f):
    col = 'HasDetections'
    return read_feather(f, columns=[col])[col].values

def multi_read_response(files):
    return np.concatenate([read_response(f) for f in files])

def data_from_feather(file, threshold=5):
    print("reading feather " + file)
    t0 = time()
    df=read_feather(file)
    tdiff = round(time() - t0)
    if tdiff > threshold:
        print(" ... that took " + str(tdiff) + " seconds")
    return datatools.Data(
        df,
        expand_categorical_as_continuous=False, #select=KEEPERS
        extra_predictors = EXTRA_PREDICTORS
    )

def train_one_gbm(feather_file):
    data = data_from_feather(feather_file)
    print("training LightGBM ...")
    lgb = Lgbm(verbose=True, declare_categoricals=True) #['SmartScreen'])
    lgb.train(data)
    lgb.freeze()
    return lgb

def train():
    models = [train_one_gbm(f) for f in TRAIN_PATHS]
    pickle.dump(models, open(MODELS_PATH, "wb"))

def predict(cross=False, test_filepaths=[TEST_PATH]):
    models = pickle.load(open(MODELS_PATH, "rb"))
    predictions = list()
    for k, filepath in enumerate(test_filepaths):
        data = data_from_feather(filepath)
        if cross:
            k_models = [m for i,m in enumerate(models) if i != k]
            assert len(k_models) == len(models) - 1
        else:
            k_models = models
        print('Scoring on group ' + str(k))
        preds = pd.DataFrame({
            'model_'+str(k): m.predict(data.X) for k, m in enumerate(k_models)
        })
        predictions += preds.mean(axis=1).tolist()
    return predictions

# print("#### Train the models ####")
# train()
#
# print("#### Evaluate via ensemble cross-validation ####")
# cv = pd.DataFrame({'truth': multi_read_response(TRAIN_PATHS)})
# cv['pred'] = predict(cross=True, test_filepaths=TRAIN_PATHS)
# print('Cross validation auc: ' + str(stats.auc(cv)))

print("#### Generate the submission ####")
df = pd.read_csv(SAMPLE_PATH)
df['HasDetections'] = predict()
df.to_csv(SUBMIT_PATH, index=False)

### Performance log
#categoricals off: 0.72872
# - after refactor indices: 0.731376
# - fix learning rate typo: 0.712077
# - retune: 0.718696
#categoricals on:
# - 0.719357
# - include categoricals as continuous 0.71975
#   - downselect features 0.71769
#   - refactor version indices 0.718869
# - retune -> 0.725416
# - with pydens -> 0.72495
