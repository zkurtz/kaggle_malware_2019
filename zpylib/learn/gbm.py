import copy
from abc import ABC, abstractmethod
import os
import pandas as pd
import pdb
import pickle
from psutil import cpu_count
import tempfile
from time import time
import warnings

with warnings.catch_warnings():
    warnings.simplefilter("ignore")
    import lightgbm as lgb

class AbstractLearner(ABC):
    def __init__(self, params = None):
        self.params = self.default_params()
        if params is not None:
            self.params.update(copy.deepcopy(params))

    @abstractmethod
    def default_params(self):
        pass

    @abstractmethod
    def train(self, data):
        pass

    @abstractmethod
    def predict(self, X):
        pass

    def vp(self, string):
        if self.verbose:
            print(string)


class Lgbm(AbstractLearner):
    def __init__(self, params=None, verbose=False, declare_categoricals=True):
        super().__init__(params)
        self.nround = self.params.pop('num_boost_round')
        self.verbose=verbose
        self.declare_categoricals = declare_categoricals

    def default_params(self):
        return {
            'task': 'train',
            'boosting_type': 'gbdt',
            'objective': 'xentropy',
            'learning_rate': 0.1,
            'num_leaves': 80,
            'min_data_in_leaf': 5,
            'verbose': -1,
            'num_boost_round': 60,
            'num_threads': cpu_count(logical=False)
        }

    def as_lgb_data(self, data):
        cat = self.declare_categoricals
        if isinstance(cat, bool):
            if cat:
                self.categoricals = data.coltypes.categorical
            else:
                self.vp("Declaring no categorical variables for lightgbm")
                self.categoricals = []
        else:
            assert isinstance(cat, list)
            self.categoricals = []
        self.categoricals = [p for p in self.categoricals if p in data.X.columns]
        self.features = data.X.columns.tolist()
        return lgb.Dataset(
            data.X,
            data.y,
            feature_name=self.features,
            categorical_feature=self.categoricals
        )

    def train(self, data):
        '''
        :param data: a data.Data instance
        '''
        t0 = time()
        ld = self.as_lgb_data(data)
        self.bst = lgb.train(
            params=copy.deepcopy(self.params),
            train_set=ld,
            num_boost_round=self.nround,
            verbose_eval=False,
            feature_name=self.features,
            categorical_feature=self.categoricals
        )
        tdiff = str(round(time() - t0))
        self.vp('LightGBM training took ' + tdiff + ' seconds')

    def cv(self, data):
        ld = self.as_lgb_data(data)
        cvres = lgb.cv(
            params=copy.deepcopy(self.params),
            train_set=ld,
            num_boost_round=self.nround,
            verbose_eval=False,
            feature_name=self.features,
            categorical_feature=self.categoricals
        )
        pdb.set_trace()

    def predict(self, X):
        return self.bst.predict(X)

    def freeze(self):
        assert self.bst is not None
        _, filename = tempfile.mkstemp()
        self.bst.save_model(filename)
        with open(filename, 'rb') as file:
            self.bst_binary = file.read()
        os.remove(filename)

    def thaw(self):
        self.bst = pickle.loads(self.bst_binary)

    def importance(self):
        return pd.DataFrame({
            'feature': self.features,
            'gain': self.bst.feature_importance(importance_type='gain')
        }).sort_values('gain', ascending=False
        ).reset_index(drop=True)

