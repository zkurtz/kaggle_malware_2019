import numpy as np
import pandas as pd
import pdb

from . import data_path as dp
from . import train_colnames

def size2dtype(n):
    if n+1 < 2**7:
        return np.int8
    elif n+1 < 2**15:
        return np.int16
    elif n+1 < 2**31:
        return np.int32
    else:
        return np.float64

def best_dtype(row):
    if row.is_categorical or (row.initial_dtype[:3]=='int'):
        return size2dtype(row['nunique'])
    return np.float64

def build_refactored_metadata():
    predcols = train_colnames()
    md = {col: pd.read_csv(dp('metadata/' + col)) for col in predcols}
    mdf = pd.DataFrame({
        'colname': predcols,
        'nunique': [md[col].shape[0] for col in predcols],
        'example': [md[col][col][0] for col in predcols],
        'initial_dtype': [md[col][col].dtype.name for col in predcols]
    })
    #df = pd.read_csv(dp('refactored/train.csv'), nrows=100)
    #mdf['new_pd_dtype'] = [df[col].dtype.name for col in predcols]
    mdf['is_categorical'] = [
        0 + (
            (md[col][col].dtype.name=='object')
            or ('Identifier' in col)
            or (md[col].shape[0] < 4)
        )
        for col in predcols
    ]
    mdf['best_dtype'] = [best_dtype(r) for i,r in mdf.iterrows()]
    return mdf

if __name__=='__main__':
    mdf = build_refactored_metadata()
    pdb.set_trace()
    categorical_predictors = mdf[mdf.is_categorical == 1].colname.tolist()
    continuous_predictors = mdf[mdf.is_categorical == 0].colname.tolist()
    "['" + "', '".join(categorical_predictors) + "']"
    "['" + "', '".join(continuous_predictors) + "']"
    mdf[mdf.is_categorical == 1]['nunique'].max()
    # pcols = data.predictor_cols
    # type_cols = [s for s in pcols if 'Type' in s]
    # pcols = set(pcols) - set(type_cols)
    # is_cols = [s for s in pcols if '_Is' in s]
    # pcols = set(pcols) - set(is_cols)
    # id_cols = [s for s in pcols if 'Identifier' in s]
    # pcols = set(pcols) - set(id_cols)
    # data.X[list(pcols)].describe()
    #
